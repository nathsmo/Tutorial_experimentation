{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid_search_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathsmo/Tutorial_experimentation/blob/master/Grid_search_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO4HlTQPcTaQ",
        "colab_type": "text"
      },
      "source": [
        "# Grid Search for model tuning\n",
        "\n",
        "## Nathalia Morales \n",
        "###  Tutorial by Rohan Joseph  from \"Towards Data Science\"\n",
        "\n",
        "\n",
        "* Link to tutorial: https://towardsdatascience.com/grid-search-for-model-tuning-3319b259367e\n",
        "\n",
        "  \n",
        " * Objetive:\n",
        "   * The  objective of this analysis is to find pattern and discover statistics. Even if Machine Learning models are used to try to predict the data it is only for investigation purposes. This is for research and leisure purposes only, no real application is to be intended from this investigation. If you have questions about the data please ask the owner of the dataset.\n",
        "   \n",
        "* Disclaimer:\n",
        "  * The author of this report is not owner not intends to take profit or recognition from the data used in this report. This report is used as a demonstration of technical skills and not for lucrative purposes. All of the findings in this report are meant for teaching purposes only. All the models in this report are meant for teaching purposes only.  The data used in this report is publicly available for anyone in the link above or specified in the tutorial from origin.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqkWlGEndMd4",
        "colab_type": "text"
      },
      "source": [
        "## Libraries Used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPWbHmoCdMlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azTQdBPJdPTb",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Import the dataset and view the top 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quMhyXlbdBVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "8778e343-2146-4df2-b640-0fb4b3533db3"
      },
      "source": [
        "#import data\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data',header=None)\n",
        "\n",
        "#set column names\n",
        "data.columns = ['Sample Code Number','Clump Thickness','Uniformity of Cell Size',\n",
        "                                                        'Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size',\n",
        "                                                        'Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
        "#view top 10 rows\n",
        "data.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample Code Number</th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bare Nuclei</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1017122</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1018099</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1018561</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1033078</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1033078</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sample Code Number  Clump Thickness  ...  Mitoses  Class\n",
              "0             1000025                5  ...        1      2\n",
              "1             1002945                5  ...        1      2\n",
              "2             1015425                3  ...        1      2\n",
              "3             1016277                6  ...        1      2\n",
              "4             1017023                4  ...        1      2\n",
              "5             1017122                8  ...        1      4\n",
              "6             1018099                1  ...        1      2\n",
              "7             1018561                2  ...        1      2\n",
              "8             1033078                2  ...        5      2\n",
              "9             1033078                4  ...        1      2\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_68zowf4gPBg",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Clean the data and rename the class values as 0/1 for model building (where 1 represents a malignant case). Also, let’s observe the distribution of the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJEH7Q4OgPOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7cc2c8ea-cfd3-42c2-cbcc-49c99c85242d"
      },
      "source": [
        "data = data.drop(['Sample Code Number'],axis=1) #Drop 1st column\n",
        "data = data[data['Bare Nuclei'] != '?'] #Remove rows with missing data\n",
        "data['Class'] = np.where(data['Class'] ==2,0,1) #Change the Class representation\n",
        "data['Class'].value_counts() #Class distribution"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    444\n",
              "1    239\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsL3NvfbhWVc",
        "colab_type": "text"
      },
      "source": [
        "There are 444 benign and 239 malignant cases.\n",
        "\n",
        "\n",
        "\n",
        "## Step 3: \n",
        "\n",
        "Before building a classification model, we'll build a Dummy Classifier to determine the ‘baseline’ performance. This answers the question — ‘What would be the success rate of the model, if one were simply guessing?’ The dummy classifier we are using will simply predict the majority class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-khoT2GhWeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e64fc104-d4f1-41e7-8b12-0a583b3401a9"
      },
      "source": [
        "#Split data into attributes and class\n",
        "X = data.drop(['Class'],axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "#perform training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "#Dummy Classifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier(strategy= 'most_frequent').fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "#Distribution of y test\n",
        "print('y actual : \\n' +  str(y_test.value_counts()))\n",
        "\n",
        "#Distribution of y predicted\n",
        "print('y predicted : \\n' + str(pd.Series(y_pred).value_counts()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y actual : \n",
            "0    103\n",
            "1     68\n",
            "Name: Class, dtype: int64\n",
            "y predicted : \n",
            "0    171\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tft5EKEiXQl",
        "colab_type": "text"
      },
      "source": [
        "* here we can see that the model predicted that all the values are of the first type because it is the mayority class. Models may tend to do this is they aren't tunned correctly.\n",
        "\n",
        "## 4. Calculate the evaluation metrics of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukoi72C1ikrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "4066749e-0118-4261-e927-64a2b7ae1723"
      },
      "source": [
        "# Model Evaluation metrics \n",
        "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
        "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
        "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
        "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
        "print('F1 Score : ' + str(f1_score(y_test,y_pred)))\n",
        "\n",
        "#Dummy Classifier Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.6023391812865497\n",
            "Precision Score : 0.0\n",
            "Recall Score : 0.0\n",
            "F1 Score : 0.0\n",
            "Confusion Matrix : \n",
            "[[103   0]\n",
            " [ 68   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmMshES0iwSZ",
        "colab_type": "text"
      },
      "source": [
        "* The accuracy of the model is 60.2%, but this is a case where accuracy may not be the best metric to evaluate the model. So, let’s take a look at the other evaluation metrics.\n",
        "\n",
        "## 5. Now that we have the baseline accuracy, let’s build a Logistic regression model with default parameters and evaluate the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbKhbaSVi4Uc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "a1961895-a2e0-47dd-dea9-8170da3c0391"
      },
      "source": [
        "#Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression().fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Evaluation metrics \n",
        "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
        "\n",
        "\n",
        "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
        "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
        "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
        "print('F1 Score : ' + str(f1_score(y_test,y_pred)))\n",
        "\n",
        "#Logistic Regression Classifier Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('\\n Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.9473684210526315\n",
            "Precision Score : 0.9836065573770492\n",
            "Recall Score : 0.8823529411764706\n",
            "F1 Score : 0.9302325581395349\n",
            "\n",
            " Confusion Matrix : \n",
            "[[102   1]\n",
            " [  8  60]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvAXIywCjGvV",
        "colab_type": "text"
      },
      "source": [
        "* By fitting the Logistic Regression model with the default parameters, we have a much ‘better’ model. The accuracy is 94.7% and at the same time, the Precision is a staggering 98.3%. Now, let’s take a look at the confusion matrix again for this model results again :\n",
        "\n",
        "* Let’s try to minimize the false negatives by using Grid Search to find the optimal parameters. Grid search can be used to improve any specific evaluation metric.\n",
        "\n",
        "## 6. Grid Search to maximize Recall\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRexWIoAjf8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = LogisticRegression()\n",
        "grid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
        "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall')\n",
        "grid_clf_acc.fit(X_train, y_train)\n",
        "\n",
        "#Predict values based on new parameters\n",
        "y_pred_acc = grid_clf_acc.predict(X_test)\n",
        "\n",
        "# New Model Evaluation metrics \n",
        "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))\n",
        "print('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))\n",
        "print('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))\n",
        "print('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))\n",
        "\n",
        "#Logistic Regression (Grid Search) Confusion matrix\n",
        "confusion_matrix(y_test,y_pred_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wztiN5y5j7T3",
        "colab_type": "text"
      },
      "source": [
        "The hyperparameters we tuned are:\n",
        "\n",
        "* Penalty: l1 or l2 which species the norm used in the penalization.\n",
        "* C: Inverse of regularization strength- smaller values of C specify stronger regularization.\n",
        "\n",
        "Also, in Grid-search function, we have the scoring parameter where we can specify the metric to evaluate the model on (We have chosen recall as the metric). From the confusion matrix below, we can see that the number of false negatives has reduced, however, it is at the cost of increased false positives. The recall after grid search has jumped from 88.2% to 91.1%, whereas the precision has dropped to 87.3% from 98.3%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCOkzkoIkR5B",
        "colab_type": "text"
      },
      "source": [
        "# Personal Final Thoughts\n",
        "\n",
        "* Grid Search is a great way to tune in a machine learning model in order to obtain better results in the prediction of the data. \n",
        "* I will try the Grid Search with another dataset and other models soon to see it's results in varying circumstances.\n",
        "* I need to understand this \"Grid Search\" mode deeply to understand it's implication in the model's results.\n",
        "\n",
        "This tutorial was done on June 26, 2019.\n",
        "\n",
        "\n",
        "## Updates"
      ]
    }
  ]
}